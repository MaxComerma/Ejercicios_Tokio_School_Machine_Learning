{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "89b71ed5-8c08-462d-a3f3-bdfaa4b03bb5",
      "metadata": {
        "id": "89b71ed5-8c08-462d-a3f3-bdfaa4b03bb5"
      },
      "source": [
        "# Regresión lineal: Regularización\n",
        "M2U3 - Ejercicio 2\n",
        "\n",
        "## ¿Qué vamos a hacer?\n",
        "- Implementar la función de coste regularizada para la regresión lineal multivariable\n",
        "- Implementar la regularización para el gradient descent\n",
        "\n",
        "Recuerda seguir las instrucciones para las entregas de prácticas indicadas en [Instrucciones entregas](https://github.com/Tokio-School/Machine-Learning/blob/main/Instrucciones%20entregas.md)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "192b9db2-3c8c-4412-8a3e-059b0a4bf801",
      "metadata": {
        "id": "192b9db2-3c8c-4412-8a3e-059b0a4bf801"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27b8fa69-2cd8-4002-ab2c-13a5ae4ff396",
      "metadata": {
        "id": "27b8fa69-2cd8-4002-ab2c-13a5ae4ff396"
      },
      "source": [
        "## Creación de un dataset sintético\n",
        "\n",
        "Para comprobar tu implementación de una función de coste y gradient descent regularizado, rescata tus celdas de los notebooks anteriores acerca de datasets sintéticos y genera un dataset para este ejercicio.\n",
        "\n",
        "No olvides añadirle un término de bias a la *X* y un término de error a la *Y*, inicializado a 0 por ahora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f1b400b5-27b7-4ed9-b950-1475b0d722a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1b400b5-27b7-4ed9-b950-1475b0d722a5",
        "outputId": "e9d2373c-6126-4a42-fde5-7878e0b5e17e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theta a estimar y sus dimensiones:\n",
            "[0.92691383 0.61857306 0.62626344 0.12639697]\n",
            "(4,)\n",
            "\n",
            "Primeras 10 filas de X:\n",
            "[[ 1.         -0.81126272 -0.34758769 -0.03401943]\n",
            " [ 1.         -0.92766097 -0.10534224 -0.11439129]\n",
            " [ 1.         -0.93509459 -0.01384949 -0.31813497]\n",
            " [ 1.          0.25490999 -0.61852029  0.43625633]\n",
            " [ 1.         -0.03294079  0.37250579  0.6749047 ]\n",
            " [ 1.          0.77144682  0.54339245  0.33026595]\n",
            " [ 1.         -0.6120878   0.05395429  0.30548144]\n",
            " [ 1.         -0.80708146 -0.21490029 -0.64165936]\n",
            " [ 1.         -0.3562002   0.0655629   0.50524808]\n",
            " [ 1.         -0.28182704  0.17994046 -0.60046792]]\n",
            "\n",
            "Primeros 10 valores de Y:\n",
            "[0.20310715 0.27265704 0.29960478 0.75237911 1.22513021 1.78616149\n",
            " 0.62069433 0.21198699 0.81149945 0.78937602]\n",
            "\n",
            "Dimensiones de X e Y:\n",
            "(1000, 4) (1000,) (1000,)\n"
          ]
        }
      ],
      "source": [
        "# TODO: Genera un dataset sintéitico manualmente, con término de bias y término de error inicializado a 0\n",
        "\n",
        "m = 1000\n",
        "n = 3\n",
        "\n",
        "X = np.random.uniform(-1, 1, size=(m, n))\n",
        "\n",
        "X = np.insert(X, 0, values=np.ones(m), axis=1)\n",
        "\n",
        "Theta_verd = np.random.rand(n + 1)\n",
        "\n",
        "Y = np.matmul(X, Theta_verd)\n",
        "\n",
        "error = 0\n",
        "\n",
        "\n",
        "# Comprueba los valores y dimensiones de los vectores\n",
        "print(\"Theta a estimar y sus dimensiones:\")\n",
        "print(Theta_verd)\n",
        "print(Theta_verd.shape)\n",
        "\n",
        "print(\"\\nPrimeras 10 filas de X:\")\n",
        "print(X[:10, :])\n",
        "\n",
        "print(\"\\nPrimeros 10 valores de Y:\")\n",
        "print(Y[:10])\n",
        "\n",
        "print(\"\\nDimensiones de X e Y:\")\n",
        "print(X.shape, Y.shape, Y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37d1e349-ffff-4df9-9597-17e6b71a7806",
      "metadata": {
        "id": "37d1e349-ffff-4df9-9597-17e6b71a7806"
      },
      "source": [
        "## Función de coste regularizada\n",
        "\n",
        "Ahora vamos a modificar nuestra implementación de la función de coste de ejercicios anteriores para añadirle el término de regularización.\n",
        "\n",
        "Recuerda que la función de coste regularizada es:\n",
        "\n",
        "$$ h_\\theta(x^i) = Y = X \\times \\Theta^T $$\n",
        "$$J_\\theta = \\frac{1}{2m} [\\sum\\limits_{i=0}^{m} (h_\\theta(x^i)-y^i)^2 + \\lambda \\sum\\limits_{j=1}^{n} \\theta^2_j]$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e86f2237-8286-40db-bf9c-14e5da6b298c",
      "metadata": {
        "id": "e86f2237-8286-40db-bf9c-14e5da6b298c"
      },
      "outputs": [],
      "source": [
        "# TODO: Implementa la función de coste regularizada siguiendo la siguiente plantilla\n",
        "\n",
        "def regularized_cost_function(x, y, theta, lambda_=0.):\n",
        "\n",
        "    m = len(y)  # número de ejemplos\n",
        "\n",
        "    # Predicciones del modelo\n",
        "    predictions = x @ theta\n",
        "    error = predictions - y\n",
        "\n",
        "    # Coste base (MSE)\n",
        "    cost = (1 / (2 * m)) * np.sum(error ** 2)\n",
        "\n",
        "    # Regularización (no incluye theta[0])\n",
        "    reg_term = (lambda_ / (2 * m)) * np.sum(theta[1:] ** 2)\n",
        "\n",
        "    j = cost + reg_term\n",
        "\n",
        "    # Asegurar que devolvemos float\n",
        "    return float(j)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bdd42e2-4677-4aab-b76c-f48a2d89c52b",
      "metadata": {
        "id": "1bdd42e2-4677-4aab-b76c-f48a2d89c52b"
      },
      "source": [
        "*NOTA:* Comprueba que la función devuelve un valor float simplemente, y no un array o matriz. Utiliza el método `ndarray.resize((size0, size1))` si necesitas cambiar las dimensiones de cualquier array antes de multliplicarlo con `np.matmul()` y asegúrate que las dimensiones del resultado cuadren, o devuelve `j[0,0]` como valor `float`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71362cca-7836-4e76-b05e-1f8036b2566a",
      "metadata": {
        "id": "71362cca-7836-4e76-b05e-1f8036b2566a"
      },
      "source": [
        "Como el dataset sintético tiene el término de error a 0, el resultado de la función de coste para la *Theta_verd* con parámetro *lambda* = 0 debe ser exactamente 0.\n",
        "\n",
        "Al igual que antes, según nos alejamos con valores de $\\theta$ diferentes, el coste debe aumentar. Del mismo modo, a mayor parámetro de regularización *lambda*, mayor penalización y coste, y a mayor valor de *Theta*, también mayor penalización y coste.\n",
        "\n",
        "Comprueba tu implementación en estas 5 circunstancias:\n",
        "1. Usando *Theta_verd* y con *lambda* a 0, el coste debe seguir siendo 0.\n",
        "1. Con *lambda* 0 aún, según los valores de *theta* se alejen de *Theta_verd*, el coste debe ser mayor.\n",
        "1. Usando *Theta_verd* y con *lambda* distinta de 0, el coste ahora debe ser mayor de 0.\n",
        "1. Con *lambda* distinta de 0, para una *theta* distinta a *Theta_verd* el coste debe ser mayor que con *lambda* igual a 0.\n",
        "1. Con *lambda* distinta de 0, cuanto mayores sean los valores de los coeficientes de *theta* (en sentido positivo o negativo), mayor será la penalización y el coste.\n",
        "\n",
        "Recordamos que el valor de *lambda* siempre debe ser positivo y generalmente menor de 0: `[0, 1e-1, 3e-1, 1e-2, 3e-2, ...]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ca11d5ff-ea2c-4dbb-b8f0-b01801dec7cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca11d5ff-ea2c-4dbb-b8f0-b01801dec7cc",
        "outputId": "57d7a589-e190-4719-aebd-db353d22f407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coste del modelo:\n",
            "0.0\n",
            "Theta comprobada y Theta real:\n",
            "[0.92691383 0.61857306 0.62626344 0.12639697]\n",
            "[0.92691383 0.61857306 0.62626344 0.12639697]\n"
          ]
        }
      ],
      "source": [
        "# TODO: Comprueba la implementación de tu función de coste regularizada en dichas circunstancias\n",
        "\n",
        "theta = Theta_verd    # Modifica y comprueba varios valores de theta\n",
        "\n",
        "j = regularized_cost_function(X, Y, theta)\n",
        "\n",
        "print(\"Coste del modelo:\")\n",
        "print(j)\n",
        "print(\"Theta comprobada y Theta real:\")\n",
        "print(theta)\n",
        "print(Theta_verd)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimento 2\n",
        "theta = Theta_verd + 0.4\n",
        "j = regularized_cost_function(X, Y, theta)\n",
        "\n",
        "print(\"Coste del modelo:\")\n",
        "print(j)\n",
        "print(\"Theta comprobada y Theta real:\")\n",
        "print(theta)\n",
        "print(Theta_verd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh9ZO1FdBSbe",
        "outputId": "afaa12ec-042a-4760-cf87-f1f20207381a"
      },
      "id": "Sh9ZO1FdBSbe",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coste del modelo:\n",
            "0.1648547999052746\n",
            "Theta comprobada y Theta real:\n",
            "[1.32691383 1.01857306 1.02626344 0.52639697]\n",
            "[0.92691383 0.61857306 0.62626344 0.12639697]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimento 3\n",
        "theta = Theta_verd\n",
        "j = regularized_cost_function(X, Y, theta, lambda_ = 0.1)\n",
        "\n",
        "print(\"Coste del modelo:\")\n",
        "print(j)\n",
        "print(\"Theta comprobada y Theta real:\")\n",
        "print(theta)\n",
        "print(Theta_verd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU_IDRv-BWVJ",
        "outputId": "6815a212-c942-4753-b83a-1ce50e535e07"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coste del modelo:\n",
            "3.954073608354915e-05\n",
            "Theta comprobada y Theta real:\n",
            "[0.92691383 0.61857306 0.62626344 0.12639697]\n",
            "[0.92691383 0.61857306 0.62626344 0.12639697]\n"
          ]
        }
      ],
      "id": "QU_IDRv-BWVJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimento 4\n",
        "theta = Theta_verd + 0.4\n",
        "j = regularized_cost_function(X, Y, theta, lambda_ = 3e-1)\n",
        "\n",
        "print(\"Coste del modelo:\")\n",
        "print(j)\n",
        "print(\"Theta comprobada y Theta real:\")\n",
        "print(theta)\n",
        "print(Theta_verd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emT_NjHDBWeu",
        "outputId": "41391e17-a306-44c4-c4f9-37dde7a9382f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coste del modelo:\n",
            "0.16520997012978542\n",
            "Theta comprobada y Theta real:\n",
            "[1.32691383 1.01857306 1.02626344 0.52639697]\n",
            "[0.92691383 0.61857306 0.62626344 0.12639697]\n"
          ]
        }
      ],
      "id": "emT_NjHDBWeu"
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimento 5\n",
        "theta = Theta_verd + 0.8\n",
        "j = regularized_cost_function(X, Y, theta, lambda_ = 3e-1)\n",
        "\n",
        "print(\"Coste del modelo:\")\n",
        "print(j)\n",
        "print(\"Theta comprobada y Theta real:\")\n",
        "print(theta)\n",
        "print(Theta_verd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nWQUwjyBWl2",
        "outputId": "3602a0ac-4742-406b-dd88-7b285704c480"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coste del modelo:\n",
            "0.6601549178618694\n",
            "Theta comprobada y Theta real:\n",
            "[1.72691383 1.41857306 1.42626344 0.92639697]\n",
            "[0.92691383 0.61857306 0.62626344 0.12639697]\n"
          ]
        }
      ],
      "id": "-nWQUwjyBWl2"
    },
    {
      "cell_type": "markdown",
      "id": "81b9b45f-a805-471e-bcf2-ed4b978e77a1",
      "metadata": {
        "tags": [],
        "id": "81b9b45f-a805-471e-bcf2-ed4b978e77a1"
      },
      "source": [
        "## Gradient descent regularizado\n",
        "\n",
        "Ahora vamos a regularizar también el entrenamiento por gradient descent. Vamos a modificar las actualizaciones de *Theta* para que ahora contengan también el parámetro de regularización *lambda*:\n",
        "\n",
        "$$ \\theta_0 := \\theta_0 - \\alpha \\frac{1}{m} \\sum_{i=0}^{m}(h_\\theta (x^i) - y^i) x_0^i $$\n",
        "$$ \\theta_j := \\theta_j - \\alpha [\\frac{1}{m} \\sum_{i=0}^{m}(h_\\theta (x^i) - y^i) x_j^i + \\frac{\\lambda}{m} \\theta_j]; \\space j \\in [1, n] $$\n",
        "$$ \\theta_j := \\theta_j (1 - \\alpha \\frac{\\lambda}{m}) - \\alpha \\frac{1}{m} \\sum_{i=0}^{m}(h_\\theta (x^i) - y^i) x_j^i; \\space j \\in [1, n] $$\n",
        "\n",
        "Recuerda basarte de nuevo en tu implementación anterior de la función de descenso de gradiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "340bbcb9-5f11-4284-8d6c-2c673ef60051",
      "metadata": {
        "id": "340bbcb9-5f11-4284-8d6c-2c673ef60051"
      },
      "outputs": [],
      "source": [
        "def regularized_gradient_descent(x, y, theta, alpha, lambda_=0., e=1e-6, iter_=1000):\n",
        "\n",
        "    m, n = x.shape\n",
        "    j_hist = []\n",
        "\n",
        "    theta = theta.copy()  # evitar modificar el original\n",
        "\n",
        "    for k in range(iter_):\n",
        "        predictions = x @ theta\n",
        "        error = predictions - y\n",
        "\n",
        "        theta_iter = theta.copy()\n",
        "\n",
        "        for j in range(n):\n",
        "            grad = (1/m) * np.sum(error * x[:, j])  # gradiente base\n",
        "\n",
        "            if j > 0:\n",
        "                theta_iter[j] = theta[j]*(1 - alpha*lambda_/m) - alpha*grad\n",
        "            else:\n",
        "                theta_iter[j] = theta[j] - alpha*grad\n",
        "\n",
        "        theta = theta_iter\n",
        "\n",
        "        # Calculamos el coste con regularización\n",
        "        cost = regularized_cost_function(x, y, theta, lambda_)\n",
        "        j_hist.append(cost)\n",
        "\n",
        "        # Comprobamos convergencia\n",
        "        if k > 0 and abs(j_hist[-2] - j_hist[-1]) < e:\n",
        "            print(f\"Converge en la iteración nº {k}\")\n",
        "            break\n",
        "    else:\n",
        "        print(\"Nº máximo de iteraciones alcanzado\")\n",
        "\n",
        "    return j_hist, theta\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "182e39cc-536d-46fa-9ec1-e7fa4b654803",
      "metadata": {
        "id": "182e39cc-536d-46fa-9ec1-e7fa4b654803"
      },
      "source": [
        "*Nota*: Recuerda que las plantillas de código son sólo una ayuda. En ocasiones, puede que quieras usar un código diferente con la misma funcionalidad, p. ej. que itere sobre los elementos de otra forma, etc. ¡Síentete libre de modificarlos a tu antojo!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcfea771-4dc6-45ed-824d-194542993aa2",
      "metadata": {
        "id": "fcfea771-4dc6-45ed-824d-194542993aa2"
      },
      "source": [
        "## Comprobación del gradient descent regularizado\n",
        "\n",
        "Para comprobar tu implementación de nuevo, comprueba con *lambda* a 0 usando varios valores de *theta_ini*, tanto con la *Theta_verd* como valores cada vez más alejados de ella, y comprueba que finalmente el modelo converge a la *Theta_verd*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d52d91e9-3a92-4a13-91aa-261f2284c424",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d52d91e9-3a92-4a13-91aa-261f2284c424",
        "outputId": "43dee7cf-a0b4-4fee-f4a2-c5e2f85cd3c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theta inicial:\n",
            "[0.2 0.2 0.2 0.2]\n",
            "Hiper-arámetros usados:\n",
            "Alpha: 0.1 Error máx.: 0.001 Nº iter 1000\n",
            "Converge en la iteración nº 25\n",
            "Tiempo de entrenamiento (s): 0.004179477691650391\n",
            "\n",
            "Últimos 10 valores de la función de coste\n",
            "[0.02641811896732234, 0.0237889108060106, 0.021504900038005717, 0.019510473868620523, 0.01775994294796295, 0.016215696868310647, 0.014846707615664546, 0.013627314995458153, 0.012536240586124904, 0.01155578692554396]\n",
            "\\Coste final:\n",
            "0.01155578692554396\n",
            "\n",
            "Theta final:\n",
            "[0.87964245 0.45306821 0.44078605 0.17107007]\n",
            "Valores verdaderos de Theta y diferencia con valores entrenados:\n",
            "[0.92691383 0.61857306 0.62626344 0.12639697]\n",
            "[-0.04727138 -0.16550485 -0.18547739  0.0446731 ]\n"
          ]
        }
      ],
      "source": [
        "# TODO: Comprueba tu implementación entrenando un modelo sobre el dataset sintético creado previamente\n",
        "\n",
        "# Crea una theta inicial con un valor dado, aleatorio o escogido a mano\n",
        "theta_ini = np.ones(X.shape[1]) * 0.2\n",
        "\n",
        "print(\"Theta inicial:\")\n",
        "print(theta_ini)\n",
        "\n",
        "alpha = 1e-1\n",
        "lambda_ = 0.\n",
        "e = 1e-3\n",
        "iter_ =  int(1e3)    # Comprueba que tu función puede admitir valores float o modifícalo\n",
        "\n",
        "print(\"Hiper-arámetros usados:\")\n",
        "print(\"Alpha:\", alpha, \"Error máx.:\", e, \"Nº iter\", iter_)\n",
        "\n",
        "t = time.time()\n",
        "j_hist, theta_final = regularized_gradient_descent(X, Y, theta_ini, alpha, lambda_=lambda_, e=e, iter_=iter_)\n",
        "print(\"Tiempo de entrenamiento (s):\", time.time() - t)\n",
        "\n",
        "# TODO: completar\n",
        "print(\"\\nÚltimos 10 valores de la función de coste\")\n",
        "print(j_hist[-10:])\n",
        "print(r\"\\Coste final:\")\n",
        "print(j_hist[-1])\n",
        "print(\"\\nTheta final:\")\n",
        "print(theta_final)\n",
        "\n",
        "print(\"Valores verdaderos de Theta y diferencia con valores entrenados:\")\n",
        "print(Theta_verd)\n",
        "print(theta_final - Theta_verd)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimento 2\n",
        "# Crea una theta inicial con un valor dado, aleatorio o escogido a mano\n",
        "theta_ini = np.ones(X.shape[1]) * 0.2\n",
        "\n",
        "print(\"Theta inicial:\")\n",
        "print(theta_ini)\n",
        "\n",
        "alpha = 1e-1\n",
        "lambda_ = 0.3\n",
        "e = 1e-3\n",
        "iter_ =  int(1e3)    # Comprueba que tu función puede admitir valores float o modifícalo\n",
        "\n",
        "print(\"Hiper-arámetros usados:\")\n",
        "print(\"Alpha:\", alpha, \"Error máx.:\", e, \"Nº iter\", iter_)\n",
        "\n",
        "t = time.time()\n",
        "j_hist, theta_final = regularized_gradient_descent(X, Y, theta_ini, alpha, lambda_=lambda_, e=e, iter_=iter_)\n",
        "print(\"Tiempo de entrenamiento (s):\", time.time() - t)\n",
        "\n",
        "# TODO: completar\n",
        "print(\"\\nÚltimos 10 valores de la función de coste\")\n",
        "print(j_hist[-10:])\n",
        "print(r\"\\Coste final:\")\n",
        "print(j_hist[-1])\n",
        "print(\"\\nTheta final:\")\n",
        "print(theta_final)\n",
        "\n",
        "print(\"Valores verdaderos de Theta y diferencia con valores entrenados:\")\n",
        "print(Theta_verd)\n",
        "print(theta_final - Theta_verd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UWRQfFSKdd7",
        "outputId": "fbf575a2-6c80-4546-c79a-6a6eedf39569"
      },
      "id": "6UWRQfFSKdd7",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theta inicial:\n",
            "[0.2 0.2 0.2 0.2]\n",
            "Hiper-arámetros usados:\n",
            "Alpha: 0.1 Error máx.: 0.001 Nº iter 1000\n",
            "Converge en la iteración nº 25\n",
            "Tiempo de entrenamiento (s): 0.0034966468811035156\n",
            "\n",
            "Últimos 10 valores de la función de coste\n",
            "[0.026485339108855806, 0.023858390800127586, 0.02157656140542039, 0.01958423888515308, 0.0178357348665732, 0.016293440110826198, 0.014926327936915755, 0.013708739622354473, 0.012619398334034117, 0.011640608294168095]\n",
            "\\Coste final:\n",
            "0.011640608294168095\n",
            "\n",
            "Theta final:\n",
            "[0.87964345 0.45287872 0.44060426 0.17097597]\n",
            "Valores verdaderos de Theta y diferencia con valores entrenados:\n",
            "[0.92691383 0.61857306 0.62626344 0.12639697]\n",
            "[-0.04727038 -0.16569434 -0.18565918  0.04457901]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimento 3\n",
        "\n",
        "m = 10000\n",
        "n = 4\n",
        "\n",
        "X = np.random.uniform(-1, 1, size=(m, n))\n",
        "\n",
        "X = np.insert(X, 0, values=np.ones(m), axis=1)\n",
        "\n",
        "Theta_verd = np.random.rand(n + 1)\n",
        "\n",
        "Y = np.matmul(X, Theta_verd)\n",
        "\n",
        "error = 0.3\n",
        "\n",
        "ruido = np.random.normal(0, error * np.abs(Y))\n",
        "Y += ruido\n",
        "# Crea una theta inicial con un valor dado, aleatorio o escogido a mano\n",
        "theta_ini = np.ones(X.shape[1]) * 0.2\n",
        "\n",
        "print(\"Theta inicial:\")\n",
        "print(theta_ini)\n",
        "\n",
        "alpha = 1e-1\n",
        "lambda_ = 10\n",
        "e = 1e-3\n",
        "iter_ =  int(1e3)    # Comprueba que tu función puede admitir valores float o modifícalo\n",
        "\n",
        "print(\"Hiper-arámetros usados:\")\n",
        "print(\"Alpha:\", alpha, \"Error máx.:\", e, \"Nº iter\", iter_)\n",
        "\n",
        "t = time.time()\n",
        "j_hist, theta_final = regularized_gradient_descent(X, Y, theta_ini, alpha, lambda_=lambda_, e=e, iter_=iter_)\n",
        "print(\"Tiempo de entrenamiento (s):\", time.time() - t)\n",
        "\n",
        "# TODO: completar\n",
        "print(\"\\nÚltimos 10 valores de la función de coste\")\n",
        "print(j_hist[-10:])\n",
        "print(r\"\\nCoste final:\")\n",
        "print(j_hist[-1])\n",
        "print(\"\\nTheta final:\")\n",
        "print(theta_final)\n",
        "\n",
        "print(\"Valores verdaderos de Theta y diferencia con valores entrenados:\")\n",
        "print(Theta_verd)\n",
        "print(theta_final - Theta_verd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOj5ADIgKd-D",
        "outputId": "2827c478-ee15-4575-87b9-260d1627624c"
      },
      "id": "FOj5ADIgKd-D",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theta inicial:\n",
            "[0.2 0.2 0.2 0.2 0.2]\n",
            "Hiper-arámetros usados:\n",
            "Alpha: 0.1 Error máx.: 0.001 Nº iter 1000\n",
            "Converge en la iteración nº 44\n",
            "Tiempo de entrenamiento (s): 0.021642208099365234\n",
            "\n",
            "Últimos 10 valores de la función de coste\n",
            "[0.09831496492319075, 0.09664506714212476, 0.09508399286687227, 0.09362443171900789, 0.09225960523629045, 0.09098322076563475, 0.08978943059251315, 0.0886727955377794, 0.08762825238454443, 0.08665108460528621]\n",
            "\\Coste final:\n",
            "0.08665108460528621\n",
            "\n",
            "Theta final:\n",
            "[0.72513108 0.64141989 0.71799738 0.64822166 0.81441259]\n",
            "Valores verdaderos de Theta y diferencia con valores entrenados:\n",
            "[0.73320741 0.77433904 0.87838037 0.77189857 0.99637205]\n",
            "[-0.00807634 -0.13291915 -0.160383   -0.12367691 -0.18195946]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m87",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
